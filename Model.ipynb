{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned file\n",
    "df = pd.read_csv(\"data/cleaned_toronto_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for Linear Regression\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Split into training and test sets with 75% for training and 25% for testing\n",
    "X_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression Model\n",
    "Lin_Reg_model = LinearRegression()\n",
    "\n",
    "# Fill in missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_LR = imputer.fit_transform(X_train_LR)\n",
    "X_test_LR = imputer.transform(X_test_LR)\n",
    "\n",
    "# Fit the model to the training set\n",
    "Lin_Reg_model.fit(X_train_LR, y_train_LR)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = Lin_Reg_model.predict(X_test_LR)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test_LR, y_pred)\n",
    "rmse = mean_squared_error(y_test_LR, y_pred, squared=False)\n",
    "r2 = r2_score(y_test_LR, y_pred)\n",
    "mae = mean_absolute_error(y_test_LR, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE on the test set is fairly large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for Random Forest\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Split into training and test sets with 75% for training and 25% for testing\n",
    "X_train_RF, X_test_RF, y_train_RF, y_test_RF = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Random Forest Regressor model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fill in missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_RF = imputer.fit_transform(X_train_RF)\n",
    "X_test_RF = imputer.transform(X_test_RF)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(X_train_RF, y_train_RF)\n",
    "\n",
    "# Use the model to make predictions on the test set\n",
    "y_pred = rf.predict(X_test_RF)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test_RF, y_pred)\n",
    "rmse = mean_squared_error(y_test_RF, y_pred, squared=False)\n",
    "r2 = r2_score(y_test_RF, y_pred)\n",
    "mae = mean_absolute_error(y_test_RF, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE score is slightly than the linear regression model. Therefore, the Random Forest model is performing better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for XGBoost\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Split into training and test sets with 70% for training and 25% for testing\n",
    "X_train_XG, X_test_XG, y_train_XG, y_test_XG = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost Model\n",
    "model = xgb.XGBRegressor(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    verbosity=0,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fill in missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_XG = imputer.fit_transform(X_train_XG)\n",
    "X_test_XG = imputer.transform(X_test_XG)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_XG, y_train_XG)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_XG)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test_XG, y_pred)\n",
    "rmse = mean_squared_error(y_test_XG, y_pred, squared=False)\n",
    "r2 = r2_score(y_test_XG, y_pred)\n",
    "mae = mean_absolute_error(y_test_XG, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for XGBoost is slightly worse but still very similar to the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for Neural Network\n",
    "X = df.drop(\"price\", axis=1).values\n",
    "y = df[\"price\"].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_NN, X_test_NN, y_train_NN, y_test_NN = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_NN = scaler.fit_transform(X_train_NN)\n",
    "X_test_NN = scaler.transform(X_test_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into PyTorch tensors\n",
    "X_train_NN = torch.tensor(X_train_NN, dtype=torch.float32)\n",
    "y_train_NN = torch.tensor(y_train_NN, dtype=torch.float32)\n",
    "X_test_NN = torch.tensor(X_test_NN, dtype=torch.float32)\n",
    "y_test_NN = torch.tensor(y_test_NN, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(36, 128) # input layer\n",
    "        self.fc2 = nn.Linear(128, 64) # hidden layer\n",
    "        self.fc3 = nn.Linear(64, 32) # hidden layer\n",
    "        self.fc4 = nn.Linear(32, 1) # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the neural network\n",
    "net = Net()\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "for epoch in range(200):\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward + backward + optimize\n",
    "    outputs = net(X_train_NN)\n",
    "    loss = criterion(outputs, y_train_NN)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/200, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the neural network on the testing set\n",
    "with torch.no_grad():\n",
    "    predictions = net(X_test_NN)\n",
    "    mse = criterion(predictions, y_test_NN)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    r2 = 1 - mse / torch.var(y_test_NN)\n",
    "    print(\"MSE:\", mse)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance is poorer than the previous models"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "323334d435dbda18355573db32188b32d4fbcf79d44848214f715dd8ef17583e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('airbnb-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
